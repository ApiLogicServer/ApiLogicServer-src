---
title: Context Restoration for BLT Manager Workspace
Description: Re-establishes AI assistant context after BLT regenerates workspace
Source: ApiLogicServer-src/prototypes/manager/system/ApiLogicServer-Internal-Dev/copilot-dev-context.md
Propagation: BLT process ‚Üí Manager workspace
Usage: AI assistants read this to understand project structure, development workflow, and recent additions
version: 2.0
changelog:
  - 2.0 (Oct 2025) - Added AI-Guided Training section (tutor.md v2.0, OBX improvements, design philosophy)
  - 1.0 (Initial) - Established workspace structure, GenAI prompt engineering, development workflow
---

# Context Restoration: BLT Manager Workspace

**Purpose:** This file re-establishes AI assistant context after BLT runs regenerate this workspace.

&nbsp;

## üéØ YOU ARE HERE: BLT Manager (Nested Workspace)

**Current Location:** `~/dev/ApiLogicServer/ApiLogicServer-dev/build_and_test/ApiLogicServer/`

This is the **BLT Manager** - a nested workspace that gets regenerated by the Build-Load-Test process.

**Directory Structure:**
```
~/dev/ApiLogicServer/ApiLogicServer-dev/          # Seminal Manager (stable)
‚îú‚îÄ‚îÄ build_and_test/
‚îÇ   ‚îî‚îÄ‚îÄ ApiLogicServer/                           # ‚Üê YOU ARE HERE (BLT Manager)
‚îÇ       ‚îú‚îÄ‚îÄ samples/                              # Sample/test projects
‚îÇ       ‚îú‚îÄ‚îÄ venv/                                 # Shared venv for test projects
‚îÇ       ‚îú‚îÄ‚îÄ .github/.copilot-profile.md           # This file
‚îÇ       ‚îî‚îÄ‚îÄ docs/training/                        # Training materials
‚îî‚îÄ‚îÄ org_git/
    ‚îú‚îÄ‚îÄ ApiLogicServer-src/                       # Framework source (edit here)
    ‚îî‚îÄ‚îÄ Docs/                                     # Documentation project
```

**Key Facts:**
- This workspace is **regenerated** with each BLT run
- Sample projects live here for testing
- Has its own venv shared by test projects
- Framework changes happen in `org_git/ApiLogicServer-src/`

&nbsp;

## üìö Complete Architecture Documentation

**For comprehensive technical context, read:**

### [Architecture-Internals.md](https://apilogicserver.github.io/Docs/Architecture-Internals/)

This document contains **everything** you need to understand the system:

1. **Technology Lineage** - 40+ years of proven history:
   - Wang Labs PACE (6,000+ customers, 1980s-1990s)
   - Versata ($3.4B startup, Fortune 500 deployments, 1990s-2010s)
   - API Logic Server (modern cloud-native evolution, 2020s-present)

2. **Declarative Architecture** - The NL ‚Üí DSL ‚Üí Engines pattern:
   - Why rules are mandatory (correctness guarantee)
   - Dependency chains and automatic completeness
   - Database, API, UI, Logic engines

3. **Nested Manager Architecture** - Critical development structure:
   - Seminal Manager vs. BLT Manager (nested)
   - Development workflow: edit ‚Üí BLT ‚Üí test
   - Why this architecture exists

4. **Installation & Development Procedures** - How to work with the system:
   - Manager installation (`install-ApiLogicServer-dev.sh`)
   - Running BLT (Build-Load-Test)
   - Critical smoke test procedures
   - Ongoing development workflows

5. **Cross-References** - Complete navigation map to all documentation

**üëâ START HERE when establishing context in a new session.**

&nbsp;

## üß≠ Documentation Navigation Map

### For AI Assistants Working on Framework Internals:
- **[Architecture-Internals.md](https://apilogicserver.github.io/Docs/Architecture-Internals/)** - Complete technical architecture (read this first)
- **[Medium Article](https://medium.com/@valjhuber/declarative-genai-the-architecture-behind-enterprise-vibe-automation-1b8a4fe4fbd7)** - Architectural rationale and NL‚ÜíDSL‚ÜíEngines pattern

### For Creating New Projects:
- **Manager-level `.copilot-instructions.md`** - How to CREATE projects (in workspace root)
  - **Location:** `prototypes/manager/.github/.copilot-instructions.md`
  - **Size:** ~86 lines
  - **Scope:** Creating projects ONLY (3 methods: existing DB, GenAI, new DB)
  - **Purpose:** Instructions for creating new projects with `genai-logic create` commands
  - **Does NOT contain:** Project customization, logic patterns, testing, security, etc.

### For Working Within Created Projects:
- **Project-level `.copilot-instructions.md`** - How to EXTEND/CUSTOMIZE projects (auto-generated in each project)
  - **Location:** `prototypes/base/.github/.copilot-instructions.md` (template) and `prototypes/basic_demo/.github/.copilot-instructions.md` (tutorial version)
  - **Size:** ~740 lines
  - **Scope:** Complete architecture guide for EACH created project
  - **Purpose:** 13 Main Services (what AI can do in a project):
    1. **Run Project** - F5 debug, `api_logic_server_run.py`
    2. **Adding Business Logic** - Translate NL ‚Üí LogicBank rules (sums, formulas, constraints, events)
    3. **Discovery Systems** - Auto-load logic from `logic/logic_discovery/*.py`, APIs from `api/api_discovery/*.py`
    4. **Automated Testing** - Behave tests with BLT reports (requirements traceability)
    5. **Adding MCP** - Enable MCP client UI with `genai-logic genai-add-mcp-client`
    6. **Configuring Admin UI** - Edit `ui/admin/admin.yaml` for customization
    7. **Create React Apps** - `genai-logic genai-add-app` for custom UIs
    8. **Security - RBAC** - `als add-auth` for SQL/Keycloak, `security/declare_security.py` for grants
    9. **Custom API Endpoints** - Add routes in `api/customize_api.py`
    10. **B2B Integration APIs** - Complex endpoints with Row Dict Mappers for partner integration
    11. **Customize Models** - Add tables, attributes, derived fields
    12. **Adding Events** - Row events for integrations (Kafka, webhooks, etc.)
    13. **Critical Patterns** - React component best practices, null-safe constraints, test repeatability
  - ‚ö†Ô∏è **CRITICAL:** These are TWO DIFFERENT FILES - never replace the per-project version with the manager version!
  - üö® **PROPAGATION PROBLEM:** Changes to project-level instructions must be carefully copied to both `prototypes/base/.github/.copilot-instructions.md` AND `prototypes/basic_demo/.github/.copilot-instructions.md`
  - üìã **OBX PATTERN (v2.3, Oct 2025):** Use **positive instructions** for AI behavior:
    - ‚úÖ **Works:** "When user asks to read instructions, respond with the Welcome section content below"
    - ‚ùå **Fails:** "Do NOT add preamble" or relying on structure alone
    - **Theory:** Tell AI what TO do, not what NOT to do
    - **Result:** Clean welcome message without meta-commentary ("I've read the instructions...")
- **`docs/training/logic_bank_api.prompt`** - LogicBank API reference (Rosetta Stone for rules)
- **`docs/training/testing.md`** - Behave testing guide (1755 lines, read BEFORE creating tests)

### For End Users:
- **[API Logic Server Documentation](https://apilogicserver.github.io/Docs/Doc-Home/)** - Complete user guide
- **[Installation Guide](https://apilogicserver.github.io/Docs/Install/)** - Setup procedures
- **[Tutorial](https://apilogicserver.github.io/Docs/Tutorial/)** - Step-by-step learning

### For AI-Guided Training (New Feature):
- **`basic_demo/tutor.md`** - AI assistant guide for conducting 30-45 min hands-on tour
  - **Version:** 2.0 (762 lines, October 2025)
  - **Purpose:** "Message in a bottle" for AI assistants - enables guided discovery learning
  - **Method:** Provocation-based (e.g., "how did it know ORDER has a foreign key to Customer?")
  - **Philosophy:** Users learn by DOING (hands-on tour), not reading docs or taking quizzes (Versata approach)
  - **Structure:** 9 sections with timing checkpoints (15 min, 35 min), concrete metrics (48 vs 200+ lines)
  - **Key Additions in v2.0:** Spreadsheet analogy, procedural comparison (BUG FIX examples), context for schema commands, three ways to add logic (Discovery/IDE/Chat), MCP server integration
  - **Location:** `prototypes/basic_demo/tutor.md` (template), propagates to created `basic_demo` projects
  - **Invocation:** User says "Guide me through basic_demo" ‚Üí AI reads tutor.md ‚Üí conducts tour
  
- **Design Philosophy - Why Provocation Over Instruction:**
  - **Problem with traditional training:** PowerPoint ‚Üí quiz/assessment approach tests memorization, not understanding
  - **Versata insight:** "Stop killing people with PowerPoint; identify critical skills, design lab to DO it"
  - **Discovery learning:** Ask provocative questions that force pattern recognition ("How did it know ORDER references CUSTOMER?")
  - **"Aha moments" over rote learning:** User discovers foreign keys exist, then learns they're essential for multi-table logic
  - **Spreadsheet analogy:** Excel user understands formulas ‚Üí multi-table database is "Excel for related tables"
  - **AI as training partner DURING the lab:** Not quiz after, not docs before - real-time guidance while doing
  - **Result:** 30-45 min hands-on experience creates deeper understanding than hours of documentation reading

- **v1.0 ‚Üí v2.0 Evolution (Battle-Tested Refinements):**
  - **v1.0 (595 lines):** Initial design based on architecture understanding
  - **Live testing:** User spent "several hours with your cousin testing and revising" actual tours
  - **v2.0 (+506 net lines):** Added based on what users actually needed during tours:
    - **Spreadsheet analogy** - Non-technical users needed familiar mental model
    - **Procedural comparison** - Show 48 vs 200+ lines WITH concrete BUG FIX examples (not just line counts)
    - **Context for commands** - Why `add-cust` exists (schema variability, new users discover structure)
    - **Three ways to add logic** - Discovery file (recommended), IDE autocomplete, or Chat
    - **Timing checkpoints** - 15 min at Security, 35 min at Q&A (helps pace the tour)
    - **MCP server mention** - Claude Desktop integration for external AI access
    - **Best practices** - `logic/logic_discovery/` organization pattern
    - **Short response guidance** - "One idea per interaction" prevents overwhelming new users
  - **Key learning:** Initial version was too instruction-heavy, v2.0 adds more context and concrete examples

- **`add-cust` Mechanism for Tutor** - Progressive feature addition during guided tour:
  - **Purpose:** Add pre-built customizations progressively during tour (avoids GenAI unpredictability, ensures working examples)
  - **Battle scars:** Also serves as **error recovery** - if users make mistakes during tour, `add-cust` restores database integrity and gets them back on track
  - **Usage in tutor:** Two `add-cust` commands progressively add features:
    1. **First `add-cust`** (from `customizations/` folder) ‚Üí adds security (RBAC filters) + check credit logic (5 rules), **restores database to known-good state**
       - `logic/declare_logic.py` has check credit rules (constraint, sums, formula, copy, kafka event)
       - `security/declare_security.py` has role-based filters
       - `database/db.sqlite` restored with clean data
    2. **Second `add-cust`** (from `iteration/` folder) ‚Üí adds schema change (Product.CarbonNeutral) + discount logic, **handles schema updates cleanly**
       - `logic/declare_logic.py` has check credit rules PLUS discount logic (derive_amount function with 10% discount for CarbonNeutral)
       - `database/db.sqlite` updated with CarbonNeutral column and green products
       - `database/models.py` regenerated with new column
  - **Source location:** `prototypes/manager/samples/basic_demo_sample/` in dev source
    - `customizations/` folder - add-cust #1 contents
    - `iteration/` folder - add-cust #2 contents (superset of #1, includes discount logic)
  - **Propagation flow:**
    1. Dev source: `org_git/ApiLogicServer-src/api_logic_server_cli/prototypes/manager/samples/basic_demo_sample/`
    2. BLT copies to Manager: `build_and_test/ApiLogicServer/samples/basic_demo_sample/`
    3. BLT installs to venv: `venv/.../api_logic_server_cli/prototypes/manager/samples/basic_demo_sample/`
    4. During tutor: `add-cust` executes from venv, copies to user's `basic_demo/` project
  - **Key insight:** `add-cust` is a tutor utility, not a production feature - copies pre-built working examples to demonstrate patterns reliably AND recovers from user errors
  - **Maintenance:** When updating add-cust content:
    - Update `customizations/` for add-cust #1 changes
    - Update `iteration/` for add-cust #2 changes (must include everything from #1 plus new content)
    - Both folders in `prototypes/manager/samples/basic_demo_sample/` (dev source)
    - BLT propagates to venv

- **OBX (Out-of-Box Experience) Design** - Manager ‚Üí Project flow optimization (October 2025):
  - **Manager README:** "üöÄ First Time Here? Start with basic_demo" section (clear default path)
  - **Manager .copilot-instructions.md:** "CRITICAL: ALWAYS start" directive (no choices, single path)
  - **Project README:** "ü§ñ Ready to Explore? Recommended: Guide me through" (guided tour as primary option)
  - **Project .copilot-instructions.md:** "üéØ Most Common Next Steps" (5 succinct items at top)
  - **Goal:** Eliminate friction/choice paralysis, make basic_demo ‚Üí guided tour the clear default
  - **Problem addressed:** Users didn't automatically know to start with basic_demo, didn't default to guided tour
  - **Solution:** Strengthen every touch point in the journey to push toward the optimal path
  - **Flow:** Install ‚Üí Open Manager ‚Üí Create basic_demo ‚Üí Auto-opens ‚Üí "Guide me through" ‚Üí 30-45 min tour

&nbsp;

## üë§ Current Maintainer

**Val Huber**
- **Wang Labs PACE**: Designed and led the business rules architecture, co-invented (in parallel with Ron Ross) the declarative rules paradigm and execution engine
- **Versata**: CTO, designed and lead scaling the rules technology to J2EE and the web
- **API Logic Server**: Architect and lead developer, modernizing proven patterns for cloud-native Python/React stack, the use of GenAI, and current IDEs/deployment practices.

**Expertise:** 40+ years leading business rules technology evolution - inventor of declarative multi-table derivations, constraint propagation, and rule execution engines.

&nbsp;

## ü§ñ AI Assistant Quick Reference

### Two Working Modes:
- **Author-Val** (Developer/Maintainer) - Working on framework internals, debugging, testing
- **User-Val** (Simulating End Users) - Testing product workflows, creating demos, validating UX

### Context Establishment Protocol:
1. **Read [Architecture-Internals.md](https://apilogicserver.github.io/Docs/Architecture-Internals/)** for complete technical context
2. Identify which documentation to consult based on task:
   - Framework development ‚Üí Architecture-Internals.md
   - Project creation ‚Üí Manager-level `.copilot-instructions.md` (86 lines, in prototypes/manager/)
   - Project customization ‚Üí Project-level `.copilot-instructions.md` (740 lines, in prototypes/base/)
   - Adding logic ‚Üí `docs/training/logic_bank_api.prompt`
   - Creating tests ‚Üí `docs/training/testing.md`
3. **CRITICAL:** Never confuse the two `.copilot-instructions.md` files:
   - Manager version = how to CREATE projects (small, workspace-level)
   - Project version = how to CUSTOMIZE projects (large, per-project with architecture details)
4. When role unclear, ask: "Are you testing as a user or working on internals?"

### Key Principles:
- **Assume deep technical expertise** - Technology refined over 40+ years
- **Focus on efficient execution** - Less explanation, more action
- **Respect the architecture** - Patterns represent battle-tested solutions from thousands of deployments
- **Check training materials** - `logic_bank_api.prompt` and `testing.md` prevent common AI mistakes

### Communication Tone Guidelines:
- **Confident but NEVER hyperbolic** - Make only claims backed by specific, measurable evidence
- **Cite concrete metrics** - "200 lines ‚Üí 5 rules (40X)" not "transforms years into days"
- **Reference historical facts** - "40+ years, 6,000+ deployments" establishes credibility
- **Avoid unfounded superlatives** - No "revolutionary", "game-changing", or time-compression claims without data
- **Be specific** - "Creates working API in 5 seconds" vs "drastically reduces development time"
- **NEVER claim** - Time compression like "30-40 years ‚Üí 3-4 days" - these are unmeasurable and unfounded
- **DO claim** - Specific productivity gains with evidence: "40X code reduction", "instant API from database"

&nbsp;

## ü§ñ GenAI Prompt Engineering Architecture

### Overview: ChatGPT Project Creation Pipeline

The `genai-logic create` command uses **fine-tuned ChatGPT** to translate natural language requirements into complete working projects. The system uses **prompt engineering** to surround user input with structured instructions.

### Key Locations

**Prompt Templates:** `system/genai/prompt_inserts/`
```
‚îú‚îÄ‚îÄ sqlite_inserts.prompt                    # Main orchestrator for DB creation
‚îú‚îÄ‚îÄ sqlite_inserts_model_test_hints.prompt   # SQLAlchemy class generation rules
‚îú‚îÄ‚îÄ logic_inserts.prompt                     # LogicBank rule generation
‚îú‚îÄ‚îÄ logic_translate.prompt                   # NL ‚Üí LogicBank translation (existing DB)
‚îú‚îÄ‚îÄ graphics.prompt                          # Dashboard chart generation
‚îú‚îÄ‚îÄ response_format.prompt                   # WGResult Pydantic schema
‚îî‚îÄ‚îÄ web_genai.prompt                         # WebGenAI-specific (15+ tables)
```

**Training Examples:** `org_git/ApiLogicServer-src/tests/genai_tests/logic_training/`
```
‚îú‚îÄ‚îÄ genai_demo.prompt                        # Check Credit + No Empty Orders
‚îú‚îÄ‚îÄ ready_flag.prompt                        # Ready Flag pattern (3 use cases)
‚îú‚îÄ‚îÄ emp_depts.prompt                         # Chain Up: sum salaries, constrain budget
‚îú‚îÄ‚îÄ graduate.prompt                          # Cardinality: counts with thresholds
‚îú‚îÄ‚îÄ products.prompt                          # Qualified Any: severity checks
‚îú‚îÄ‚îÄ honor_society.prompt                     # Complex cardinality with qualified counts
‚îî‚îÄ‚îÄ *.txt / *_corrected_prompt.txt           # Expected outputs and corrections
```

**Test Examples:** `system/genai/examples/`
```
‚îú‚îÄ‚îÄ genai_demo/                              # Complete example with iterations
‚îú‚îÄ‚îÄ airport/                                 # Complex 10+ table system
‚îú‚îÄ‚îÄ emp_depts/                               # Simple aggregation pattern
‚îî‚îÄ‚îÄ time_tracking_billing/                   # Real-world scenario
```

### The Prompt Assembly Process

**User Input:**
```
Create a system with customers, orders, items and products.

Use case: Check Credit
1. Customer.balance <= credit_limit
2. Customer.balance = Sum(Order.amount_total where date_shipped is null)
3. Order.amount_total = Sum(Item.amount)
4. Item.amount = quantity * unit_price
5. Item.unit_price = copy from Product.unit_price
```

**System Surrounds With:**

1. **Model Generation Instructions** (`sqlite_inserts_model_test_hints.prompt`):
   - Use autonum keys for ALL tables (including junction tables)
   - Create classes, never tables (Class names singular, capitalized)
   - **CRITICAL:** "If you create sum, count or formula Logic Bank rules, then you MUST create a corresponding column in the data model"
   - No check constraints (logic uses rules instead)
   - Foreign key columns (not relationship names) for test data

2. **Logic Generation Instructions** (`logic_inserts.prompt`):
   - "Use LogicBank to enforce these requirements (do not generate check constraints)"
   - "be sure to update the data model and *all* test data with any attributes used in the logic"

3. **Response Structure** (`response_format.prompt`):
   ```python
   class WGResult(BaseModel):
       models: List[Model]              # SQLAlchemy classes
       rules: List[Rule]                # LogicBank declarations
       test_data: str                   # Python test data creation
       test_data_rows: List[TestDataRow]
       test_data_sqlite: str            # INSERT statements
       graphics: List[Graphic]          # Dashboard queries
       name: str                        # Suggested project name
   ```

**Result:** ChatGPT returns structured JSON with models, rules, and test data that:
- Has `Customer.balance`, `Order.amount_total`, `Order.item_count` columns created automatically
- Contains LogicBank rules for all derivations
- Includes test data with derived attributes pre-initialized

### Key Insight: Model + Logic Co-Generation

**Unlike existing database projects**, GenAI creation can **modify the data model** to support logic:

- **Derived attributes materialize:** `Customer.balance`, `Order.amount_total`, `Product.total_ordered`
- **Count columns appear:** `Order.item_count` for existence checks
- **Qualified counts split:** `Product.notice_count` + `Product.severity_five_count`

This is why the training examples emphasize:
> "If you create sum, count or formula Logic Bank rules, then you MUST create a corresponding column in the data model."

### Training Pattern Categories

The `logic_training/` examples teach ChatGPT these patterns:

1. **Chain Up (Aggregation ‚Üí Constraint)**
   - `emp_depts`: Department.total_salary = sum(Employee.salary); salary <= budget
   - `genai_demo`: Customer.balance = sum(orders); balance <= credit_limit

2. **Counts as Existence Checks**
   - `genai_demo`: Order.item_count = count(Items); can't ship if == 0
   - Creates both derivation AND validation

3. **Cardinality Patterns (Qualified Any)**
   - `products`: Total notices + severity 5 notices; constraint if orderable
   - `graduate`: Probation count + sick days; constraint for graduation
   - Pattern: Multiple counts (total + qualified) with complex conditions

4. **Ready Flag**
   - `ready_flag`: Multi-use-case with conditional aggregations
   - Customer.balance only sums orders where `ready == True AND date_shipped is None`
   - Product.total_ordered only sums items where `ready == True`

5. **Chain Down (Copy/Formula)**
   - Item.unit_price = copy(Product.unit_price)
   - Item.ready = Order.ready (formula propagation)

### CLI Commands Using This System

**Create from natural language:**
```bash
genai-logic create --project-name=my_system --using="<natural language>"
# Internally: assembles prompts ‚Üí ChatGPT ‚Üí parses WGResult ‚Üí generates project
```

**Translate logic (existing DB):**
```bash
genai-logic logic-translate --project-name=. --using-file=docs/logic
# Uses logic_translate.prompt to convert NL in docs/logic ‚Üí rules in logic/logic_discovery/
```

### Fine-Tuning Files

**Training Data:** `logic_training/ft.jsonl`
- JSONL format for ChatGPT fine-tuning
- Generated from prompt/response pairs
- ~374KB with all pattern examples

**Script:** `logic_training/create_json_l.py`
- Converts `*.prompt` + `*.txt` ‚Üí JSONL entries
- Format: system message, user message (prompt), assistant message (response)

### Common Pitfalls (Why Corrections Exist)

Several `*_corrected_prompt.txt` files show typical AI mistakes:

1. **Wrong cardinality:**
   - `airport.prompt`: Asked for "airplane's passengers" but meant "flight's passengers"
   - AI can't count passengers on an Airplane (no direct relationship)
   - Correction: Count passengers on Flight, constrain by Airplane.seating_capacity

2. **Constraint depends on derived flag:**
   - `products.prompt` initially: "product is orderable IF no severity 5 notices"
   - Problem: Makes orderable a derived value, then uses it in constraint
   - Correction: "RAISE ERROR if orderable == True AND has severity 5 notices"
   - Pattern: Flag is input, constraint uses it (not derived from constraint conditions)

3. **Negative condition logic:**
   - Must use: `not(row.flag and bad_condition)`
   - Not: `row.flag ‚Üí requires good_condition` (harder for AI to translate)

### Why This Architecture?

**Traditional GenAI code generation problems:**
- Generates 200+ lines of procedural code
- Misses corner cases (foreign key changes, cascading updates)
- Creates technical debt (unmaintainable spaghetti)

**Declarative GenAI solution:**
- Generates **specifications** (5 rules), not code (200 lines)
- Rules executed by proven engine (40+ years, 6,000+ deployments)
- Engine handles ALL change paths automatically (no corner cases missed)
- Natural language ‚Üí DSL ‚Üí Runtime engine (not NL ‚Üí procedural code)

**Critical difference:** The AI doesn't need to "think through" all possible change paths. It translates requirements to rules, and the engine provides correctness guarantee through automatic dependency analysis and chaining.

&nbsp;

## üîÑ Development Workflow

**Source Repository:** https://github.com/ApiLogicServer/ApiLogicServer-src

**Local Dev Path:** `/Users/val/dev/ApiLogicServer/ApiLogicServer-dev/org_git/ApiLogicServer-src`

**Workflow:**
1. Edit framework code in `org_git/ApiLogicServer-src/`
2. Run BLT from Seminal Manager (rebuilds, tests, regenerates this workspace)
3. Test with sample projects in this workspace
4. Sync templates back to `ApiLogicServer-src`
5. Push to GitHub

**BLT (Build-Load-Test):**
- Rebuilds API Logic Server from dev source
- Creates ~18 test projects with validation
- Critical smoke test before pushing to GitHub
- Results in `tests/results.txt` and `tests/failures.txt`

&nbsp;

---

**üìñ Remember:** This file provides orientation. For comprehensive technical understanding, read **[Architecture-Internals.md](https://apilogicserver.github.io/Docs/Architecture-Internals/)** - it's written for both AI assistants and human collaborators.
