# Context Restoration: BLT Manager Workspace

**Purpose:** This file re-establishes AI assistant context after BLT runs regenerate this workspace.

&nbsp;

## ğŸ¯ YOU ARE HERE: BLT Manager (Nested Workspace)

**Current Location:** `~/dev/ApiLogicServer/ApiLogicServer-dev/build_and_test/ApiLogicServer/`

This is the **BLT Manager** - a nested workspace that gets regenerated by the Build-Load-Test process.

**Directory Structure:**
```
~/dev/ApiLogicServer/ApiLogicServer-dev/          # Seminal Manager (stable)
â”œâ”€â”€ build_and_test/
â”‚   â””â”€â”€ ApiLogicServer/                           # â† YOU ARE HERE (BLT Manager)
â”‚       â”œâ”€â”€ samples/                              # Sample/test projects
â”‚       â”œâ”€â”€ venv/                                 # Shared venv for test projects
â”‚       â”œâ”€â”€ .github/.copilot-profile.md           # This file
â”‚       â””â”€â”€ docs/training/                        # Training materials
â””â”€â”€ org_git/
    â”œâ”€â”€ ApiLogicServer-src/                       # Framework source (edit here)
    â””â”€â”€ Docs/                                     # Documentation project
```

**Key Facts:**
- This workspace is **regenerated** with each BLT run
- Sample projects live here for testing
- Has its own venv shared by test projects
- Framework changes happen in `org_git/ApiLogicServer-src/`

&nbsp;

## ğŸ“š Complete Architecture Documentation

**For comprehensive technical context, read:**

### [Architecture-Internals.md](https://apilogicserver.github.io/Docs/Architecture-Internals/)

This document contains **everything** you need to understand the system:

1. **Technology Lineage** - 40+ years of proven history:
   - Wang Labs PACE (6,000+ customers, 1980s-1990s)
   - Versata ($3.4B startup, Fortune 500 deployments, 1990s-2010s)
   - API Logic Server (modern cloud-native evolution, 2020s-present)

2. **Declarative Architecture** - The NL â†’ DSL â†’ Engines pattern:
   - Why rules are mandatory (correctness guarantee)
   - Dependency chains and automatic completeness
   - Database, API, UI, Logic engines

3. **Nested Manager Architecture** - Critical development structure:
   - Seminal Manager vs. BLT Manager (nested)
   - Development workflow: edit â†’ BLT â†’ test
   - Why this architecture exists

4. **Installation & Development Procedures** - How to work with the system:
   - Manager installation (`install-ApiLogicServer-dev.sh`)
   - Running BLT (Build-Load-Test)
   - Critical smoke test procedures
   - Ongoing development workflows

5. **Cross-References** - Complete navigation map to all documentation

**ğŸ‘‰ START HERE when establishing context in a new session.**

&nbsp;

## ğŸ§­ Documentation Navigation Map

### For AI Assistants Working on Framework Internals:
- **[Architecture-Internals.md](https://apilogicserver.github.io/Docs/Architecture-Internals/)** - Complete technical architecture (read this first)
- **[Medium Article](https://medium.com/@valjhuber/declarative-genai-the-architecture-behind-enterprise-vibe-automation-1b8a4fe4fbd7)** - Architectural rationale and NLâ†’DSLâ†’Engines pattern

### For Creating New Projects:
- **Manager-level `.copilot-instructions.md`** - How to CREATE projects (in workspace root)
  - **Location:** `prototypes/manager/.github/.copilot-instructions.md`
  - **Size:** ~86 lines
  - **Scope:** Creating projects ONLY (3 methods: existing DB, GenAI, new DB)
  - **Purpose:** Instructions for creating new projects with `genai-logic create` commands
  - **Does NOT contain:** Project customization, logic patterns, testing, security, etc.

### For Working Within Created Projects:
- **Project-level `.copilot-instructions.md`** - How to EXTEND/CUSTOMIZE projects (auto-generated in each project)
  - **Location:** `prototypes/base/.github/.copilot-instructions.md` (template)
  - **Size:** ~740 lines
  - **Scope:** Complete architecture guide for EACH created project
  - **Purpose:** 13 Main Services (what AI can do in a project):
    1. **Run Project** - F5 debug, `api_logic_server_run.py`
    2. **Adding Business Logic** - Translate NL â†’ LogicBank rules (sums, formulas, constraints, events)
    3. **Discovery Systems** - Auto-load logic from `logic/logic_discovery/*.py`, APIs from `api/api_discovery/*.py`
    4. **Automated Testing** - Behave tests with BLT reports (requirements traceability)
    5. **Adding MCP** - Enable MCP client UI with `genai-logic genai-add-mcp-client`
    6. **Configuring Admin UI** - Edit `ui/admin/admin.yaml` for customization
    7. **Create React Apps** - `genai-logic genai-add-app` for custom UIs
    8. **Security - RBAC** - `als add-auth` for SQL/Keycloak, `security/declare_security.py` for grants
    9. **Custom API Endpoints** - Add routes in `api/customize_api.py`
    10. **B2B Integration APIs** - Complex endpoints with Row Dict Mappers for partner integration
    11. **Customize Models** - Add tables, attributes, derived fields
    12. **Adding Events** - Row events for integrations (Kafka, webhooks, etc.)
    13. **Critical Patterns** - React component best practices, null-safe constraints, test repeatability
  - âš ï¸ **CRITICAL:** These are TWO DIFFERENT FILES - never replace the per-project version with the manager version!
  - ğŸš¨ **PROPAGATION PROBLEM:** Changes to project-level instructions must be carefully copied to `prototypes/base/.github/.copilot-instructions.md`
- **`docs/training/logic_bank_api.prompt`** - LogicBank API reference (Rosetta Stone for rules)
- **`docs/training/testing.md`** - Behave testing guide (1755 lines, read BEFORE creating tests)

### For End Users:
- **[API Logic Server Documentation](https://apilogicserver.github.io/Docs/Doc-Home/)** - Complete user guide
- **[Installation Guide](https://apilogicserver.github.io/Docs/Install/)** - Setup procedures
- **[Tutorial](https://apilogicserver.github.io/Docs/Tutorial/)** - Step-by-step learning

&nbsp;

## ğŸ‘¤ Current Maintainer

**Val Huber**
- **Wang Labs PACE**: Designed and led the business rules architecture, co-invented (in parallel with Ron Ross) the declarative rules paradigm and execution engine
- **Versata**: CTO, designed and lead scaling the rules technology to J2EE and the web
- **API Logic Server**: Architect and lead developer, modernizing proven patterns for cloud-native Python/React stack, the use of GenAI, and current IDEs/deployment practices.

**Expertise:** 40+ years leading business rules technology evolution - inventor of declarative multi-table derivations, constraint propagation, and rule execution engines.

&nbsp;

## ğŸ¤– AI Assistant Quick Reference

### Two Working Modes:
- **Author-Val** (Developer/Maintainer) - Working on framework internals, debugging, testing
- **User-Val** (Simulating End Users) - Testing product workflows, creating demos, validating UX

### Context Establishment Protocol:
1. **Read [Architecture-Internals.md](https://apilogicserver.github.io/Docs/Architecture-Internals/)** for complete technical context
2. Identify which documentation to consult based on task:
   - Framework development â†’ Architecture-Internals.md
   - Project creation â†’ Manager-level `.copilot-instructions.md` (86 lines, in prototypes/manager/)
   - Project customization â†’ Project-level `.copilot-instructions.md` (740 lines, in prototypes/base/)
   - Adding logic â†’ `docs/training/logic_bank_api.prompt`
   - Creating tests â†’ `docs/training/testing.md`
3. **CRITICAL:** Never confuse the two `.copilot-instructions.md` files:
   - Manager version = how to CREATE projects (small, workspace-level)
   - Project version = how to CUSTOMIZE projects (large, per-project with architecture details)
4. When role unclear, ask: "Are you testing as a user or working on internals?"

### Key Principles:
- **Assume deep technical expertise** - Technology refined over 40+ years
- **Focus on efficient execution** - Less explanation, more action
- **Respect the architecture** - Patterns represent battle-tested solutions from thousands of deployments
- **Check training materials** - `logic_bank_api.prompt` and `testing.md` prevent common AI mistakes

### Communication Tone Guidelines:
- **Confident but NEVER hyperbolic** - Make only claims backed by specific, measurable evidence
- **Cite concrete metrics** - "200 lines â†’ 5 rules (40X)" not "transforms years into days"
- **Reference historical facts** - "40+ years, 6,000+ deployments" establishes credibility
- **Avoid unfounded superlatives** - No "revolutionary", "game-changing", or time-compression claims without data
- **Be specific** - "Creates working API in 5 seconds" vs "drastically reduces development time"
- **NEVER claim** - Time compression like "30-40 years â†’ 3-4 days" - these are unmeasurable and unfounded
- **DO claim** - Specific productivity gains with evidence: "40X code reduction", "instant API from database"

&nbsp;

## ğŸ¤– GenAI Prompt Engineering Architecture

### Overview: ChatGPT Project Creation Pipeline

The `genai-logic create` command uses **fine-tuned ChatGPT** to translate natural language requirements into complete working projects. The system uses **prompt engineering** to surround user input with structured instructions.

### Key Locations

**Prompt Templates:** `system/genai/prompt_inserts/`
```
â”œâ”€â”€ sqlite_inserts.prompt                    # Main orchestrator for DB creation
â”œâ”€â”€ sqlite_inserts_model_test_hints.prompt   # SQLAlchemy class generation rules
â”œâ”€â”€ logic_inserts.prompt                     # LogicBank rule generation
â”œâ”€â”€ logic_translate.prompt                   # NL â†’ LogicBank translation (existing DB)
â”œâ”€â”€ graphics.prompt                          # Dashboard chart generation
â”œâ”€â”€ response_format.prompt                   # WGResult Pydantic schema
â””â”€â”€ web_genai.prompt                         # WebGenAI-specific (15+ tables)
```

**Training Examples:** `org_git/ApiLogicServer-src/tests/genai_tests/logic_training/`
```
â”œâ”€â”€ genai_demo.prompt                        # Check Credit + No Empty Orders
â”œâ”€â”€ ready_flag.prompt                        # Ready Flag pattern (3 use cases)
â”œâ”€â”€ emp_depts.prompt                         # Chain Up: sum salaries, constrain budget
â”œâ”€â”€ graduate.prompt                          # Cardinality: counts with thresholds
â”œâ”€â”€ products.prompt                          # Qualified Any: severity checks
â”œâ”€â”€ honor_society.prompt                     # Complex cardinality with qualified counts
â””â”€â”€ *.txt / *_corrected_prompt.txt           # Expected outputs and corrections
```

**Test Examples:** `system/genai/examples/`
```
â”œâ”€â”€ genai_demo/                              # Complete example with iterations
â”œâ”€â”€ airport/                                 # Complex 10+ table system
â”œâ”€â”€ emp_depts/                               # Simple aggregation pattern
â””â”€â”€ time_tracking_billing/                   # Real-world scenario
```

### The Prompt Assembly Process

**User Input:**
```
Create a system with customers, orders, items and products.

Use case: Check Credit
1. Customer.balance <= credit_limit
2. Customer.balance = Sum(Order.amount_total where date_shipped is null)
3. Order.amount_total = Sum(Item.amount)
4. Item.amount = quantity * unit_price
5. Item.unit_price = copy from Product.unit_price
```

**System Surrounds With:**

1. **Model Generation Instructions** (`sqlite_inserts_model_test_hints.prompt`):
   - Use autonum keys for ALL tables (including junction tables)
   - Create classes, never tables (Class names singular, capitalized)
   - **CRITICAL:** "If you create sum, count or formula Logic Bank rules, then you MUST create a corresponding column in the data model"
   - No check constraints (logic uses rules instead)
   - Foreign key columns (not relationship names) for test data

2. **Logic Generation Instructions** (`logic_inserts.prompt`):
   - "Use LogicBank to enforce these requirements (do not generate check constraints)"
   - "be sure to update the data model and *all* test data with any attributes used in the logic"

3. **Response Structure** (`response_format.prompt`):
   ```python
   class WGResult(BaseModel):
       models: List[Model]              # SQLAlchemy classes
       rules: List[Rule]                # LogicBank declarations
       test_data: str                   # Python test data creation
       test_data_rows: List[TestDataRow]
       test_data_sqlite: str            # INSERT statements
       graphics: List[Graphic]          # Dashboard queries
       name: str                        # Suggested project name
   ```

**Result:** ChatGPT returns structured JSON with models, rules, and test data that:
- Has `Customer.balance`, `Order.amount_total`, `Order.item_count` columns created automatically
- Contains LogicBank rules for all derivations
- Includes test data with derived attributes pre-initialized

### Key Insight: Model + Logic Co-Generation

**Unlike existing database projects**, GenAI creation can **modify the data model** to support logic:

- **Derived attributes materialize:** `Customer.balance`, `Order.amount_total`, `Product.total_ordered`
- **Count columns appear:** `Order.item_count` for existence checks
- **Qualified counts split:** `Product.notice_count` + `Product.severity_five_count`

This is why the training examples emphasize:
> "If you create sum, count or formula Logic Bank rules, then you MUST create a corresponding column in the data model."

### Training Pattern Categories

The `logic_training/` examples teach ChatGPT these patterns:

1. **Chain Up (Aggregation â†’ Constraint)**
   - `emp_depts`: Department.total_salary = sum(Employee.salary); salary <= budget
   - `genai_demo`: Customer.balance = sum(orders); balance <= credit_limit

2. **Counts as Existence Checks**
   - `genai_demo`: Order.item_count = count(Items); can't ship if == 0
   - Creates both derivation AND validation

3. **Cardinality Patterns (Qualified Any)**
   - `products`: Total notices + severity 5 notices; constraint if orderable
   - `graduate`: Probation count + sick days; constraint for graduation
   - Pattern: Multiple counts (total + qualified) with complex conditions

4. **Ready Flag**
   - `ready_flag`: Multi-use-case with conditional aggregations
   - Customer.balance only sums orders where `ready == True AND date_shipped is None`
   - Product.total_ordered only sums items where `ready == True`

5. **Chain Down (Copy/Formula)**
   - Item.unit_price = copy(Product.unit_price)
   - Item.ready = Order.ready (formula propagation)

### CLI Commands Using This System

**Create from natural language:**
```bash
genai-logic create --project-name=my_system --using="<natural language>"
# Internally: assembles prompts â†’ ChatGPT â†’ parses WGResult â†’ generates project
```

**Translate logic (existing DB):**
```bash
genai-logic logic-translate --project-name=. --using-file=docs/logic
# Uses logic_translate.prompt to convert NL in docs/logic â†’ rules in logic/logic_discovery/
```

### Fine-Tuning Files

**Training Data:** `logic_training/ft.jsonl`
- JSONL format for ChatGPT fine-tuning
- Generated from prompt/response pairs
- ~374KB with all pattern examples

**Script:** `logic_training/create_json_l.py`
- Converts `*.prompt` + `*.txt` â†’ JSONL entries
- Format: system message, user message (prompt), assistant message (response)

### Common Pitfalls (Why Corrections Exist)

Several `*_corrected_prompt.txt` files show typical AI mistakes:

1. **Wrong cardinality:**
   - `airport.prompt`: Asked for "airplane's passengers" but meant "flight's passengers"
   - AI can't count passengers on an Airplane (no direct relationship)
   - Correction: Count passengers on Flight, constrain by Airplane.seating_capacity

2. **Constraint depends on derived flag:**
   - `products.prompt` initially: "product is orderable IF no severity 5 notices"
   - Problem: Makes orderable a derived value, then uses it in constraint
   - Correction: "RAISE ERROR if orderable == True AND has severity 5 notices"
   - Pattern: Flag is input, constraint uses it (not derived from constraint conditions)

3. **Negative condition logic:**
   - Must use: `not(row.flag and bad_condition)`
   - Not: `row.flag â†’ requires good_condition` (harder for AI to translate)

### Why This Architecture?

**Traditional GenAI code generation problems:**
- Generates 200+ lines of procedural code
- Misses corner cases (foreign key changes, cascading updates)
- Creates technical debt (unmaintainable spaghetti)

**Declarative GenAI solution:**
- Generates **specifications** (5 rules), not code (200 lines)
- Rules executed by proven engine (40+ years, 6,000+ deployments)
- Engine handles ALL change paths automatically (no corner cases missed)
- Natural language â†’ DSL â†’ Runtime engine (not NL â†’ procedural code)

**Critical difference:** The AI doesn't need to "think through" all possible change paths. It translates requirements to rules, and the engine provides correctness guarantee through automatic dependency analysis and chaining.

&nbsp;

## ğŸ”„ Development Workflow

**Source Repository:** https://github.com/ApiLogicServer/ApiLogicServer-src

**Local Dev Path:** `/Users/val/dev/ApiLogicServer/ApiLogicServer-dev/org_git/ApiLogicServer-src`

**Workflow:**
1. Edit framework code in `org_git/ApiLogicServer-src/`
2. Run BLT from Seminal Manager (rebuilds, tests, regenerates this workspace)
3. Test with sample projects in this workspace
4. Sync templates back to `ApiLogicServer-src`
5. Push to GitHub

**BLT (Build-Load-Test):**
- Rebuilds API Logic Server from dev source
- Creates ~18 test projects with validation
- Critical smoke test before pushing to GitHub
- Results in `tests/results.txt` and `tests/failures.txt`

&nbsp;

---

**ğŸ“– Remember:** This file provides orientation. For comprehensive technical understanding, read **[Architecture-Internals.md](https://apilogicserver.github.io/Docs/Architecture-Internals/)** - it's written for both AI assistants and human collaborators.
